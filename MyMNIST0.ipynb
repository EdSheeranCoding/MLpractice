{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MyMNIST experiments\n",
        "me trying a couple different pytroch models on the MNIST dataset to get a feel for how they operate and to practice building models.\n",
        "\n",
        "I start by loading the data and building model somewhat \"manually\" following the example of lessons 4 from the fastai book.\n",
        "https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb\n",
        "\n",
        "I then move onto a fully linear model that learn under different optimizers (which works surprisingly well)\n",
        "\n",
        "before moving to a CNN model (trying the different optimizers as well)"
      ],
      "metadata": {
        "id": "J-hcXBPhr0ss"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iMOqF6qsrYtL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader as TorchDataLoader\n",
        "from torch.utils.data import TensorDataset\n",
        "from fastai.vision.all import *"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#reproducability\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBLuMTK0ryDR",
        "outputId": "bf5b33ca-203b-45ed-f9bb-dbef41c0fbde"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7afe948a30b0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#paths\n",
        "path = untar_data(URLs.MNIST)\n",
        "Path.BASE_DATA = path\n",
        "training = path/'training'\n",
        "testing = path/'testing'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "WVDvBDg0sG2c",
        "outputId": "b0bd97fa-5e0b-43d3-f035-bd64055b4b75"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#example image (making sure paths work)\n",
        "img_path_training = (training/'0').ls().sorted()\n",
        "img_training = img_path_training[0]\n",
        "img_training = Image.open(img_training)\n",
        "\n",
        "img_path_testing = (testing/'0').ls().sorted()\n",
        "img_testing = img_path_testing[0]\n",
        "img_testing = Image.open(img_testing)"
      ],
      "metadata": {
        "id": "V9kgdNznsPvh"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_training"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "kN8RO75wsp38",
        "outputId": "ccc26052-9c95-4ceb-dd91-8667d00a24e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABDklEQVR4AWNgGHhgPP/vfCMczjB49+fPn7fYJc0e//3z/uUfSzZMaS6bB3/+/jkV8udvFUSSCUnNzAMyQJ4Rz0EGXQxJY29GxkOljC/OT2JiRNICZoLcspnHu1KUgeHvZzQHqy39+/JCCETH3z9LUbSyb/rzwV0YZCcQ/P1zGMKAkpZ//tjDBdAlj/3dB5dj+P/3CJgD9YqPwf9NCMl//y8gOAwMoX+eScL47O1/d/HAOCA69M99GJe9+c9DdxgHTIf+mQjlGyz9sxZFioEh7O9DiEjRu7+L0OSAxv6cZCAbuunh3/vLLTAl//x5eh0Yl0ea0KUYGGSO/wHG1p+XMJtRVUg2ACV7VVEFB4IHAKxwbkRtVspVAAAAAElFTkSuQmCC\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+trwt4W1TxfrcOl6VDvlc5eRvuRL3Zj2A/wD1V0Xj74YXvgeKG5S+TU7NmMU00MRUW8oCnY/JAzu455x0FcHVnTrC51XUrbT7OMyXNzKsUaDuxOBXrmveMYfhfpk/gfwsG/tCJ1e/1TOC8pwWVR2GMLnIxg9+aboGsX/jvwD8SLrX7tpXjitrqPaAio6iTGAOMHYo98eteOV0ngC8t7D4gaDd3cyQ28V5G0kjnCqM9SfSvRvFXwjgttb1LxDr/i6xs9Hup3uY5QpeaYMxbaqjAJwe2fpXDeJ/Fdk+nHw34Whez8PKweTzADNeSA/6yRuuPReAPT046iiiiv/Z\n"
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_testing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "rZlZHVl6srch",
        "outputId": "d90fe82e-6383-4557-fccb-8268dfb33a13"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAElEQVR4AWNgoD9gRLLS9pi6j/dWhuOHkcSgTL7NX998+gcEX1+HQIUQOqenMzBcf/2JgcmL4bPtJVTN2q//PXKQ4WFgYGr483+tIKqkxb+/2VCRtl//vFEl7f/Ngwvc/TcXzGaCiTQznIQxGXYyWKBIKkl9vAyX3AdlwXTGKO05BpeEMWCSER8nwoQQNEyS4cYRhCCMBZXkZoUJINNQyXBlZEE/hj9gLtxYJEljH4YqXJLGRQJHdyKpZXD6eBzGZV7+77E5jAOhr10VATP0Zpz6988eKscCU6O54wWIaS7M8GbTaZgglA48C4pnIPjzqgJNCsiVugSWm5mBKUVXEQB0ZFOwOc4oIAAAAABJRU5ErkJggg==\n",
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/wAALCAAcABwBAREA/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/9oACAEBAAA/APn+vQtO+FF3Jo2n6vrevaRodnfKXjF5KRKU4wwTHOc569x61R8TfDi90HQY9es9TsNY0d5PKN1YuW8tvRhjgZ4zn8siuLq7o+ntq2t2Gmq4Rru4jgDEfd3MFz+tdP8AFHWU1TxpPaWpkFhpSLp9sjsTtWIbSQD0yQa1vhpcSS+EvH2nSHfaNoz3PltyBIn3WHvz+g9K81rd8FapFovjbRdRnKrDb3kbSMx4VdwBP4DJ/CvRtX+CXiTW9av9Zs77SG029uJLqK4+0nHlOxYN930NZviG60f4f+FLzwtoOqQ6pq2p/Lql/AfkjiU8RLgnrkg8+uevHl1FFFFf/9k=\n"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getDataLinear(path) -> torch.tensor:  # returns input data for linear (and manual) model\n",
        "  aux = []\n",
        "  img_list = []\n",
        "  for i in range(10):\n",
        "    temp = (path/str(i)).ls().sorted()\n",
        "    temp_t = [tensor(Image.open(o)) for o in temp]\n",
        "    img_list.append(temp_t)\n",
        "    aux.append(len(temp_t))\n",
        "  print(aux)\n",
        "  for i in range(10):\n",
        "    img_list[i] = torch.stack(img_list[i]).float() / 225\n",
        "  return torch.cat([i for i in img_list]).view(-1, 28*28), aux"
      ],
      "metadata": {
        "id": "_ve8yCGRsuKB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getDataCnn(path) -> torch.tensor:\n",
        "  aux = []\n",
        "  img_list = []\n",
        "  for i in range(10):\n",
        "    temp = (path/str(i)).ls().sorted()\n",
        "    temp_t = [tensor(Image.open(o)) for o in temp]\n",
        "    img_list.append(temp_t)\n",
        "    aux.append(len(temp_t))\n",
        "  print(aux)\n",
        "  for i in range(10):\n",
        "    img_list[i] = torch.stack(img_list[i]).float() / 225\n",
        "    img_list[i] = img_list[i].unsqueeze(1)  # adding channel dim for CNN\n",
        "  return torch.cat([i for i in img_list]), aux"
      ],
      "metadata": {
        "id": "CvT7sYf8tixx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extracting data for Linear model\n",
        "train_x_lin, aux = getDataLinear(training)\n",
        "train_y_lin = torch.tensor([i for i in range(10) for j in range(aux[i])])\n",
        "\n",
        "test_x_lin, aux = getDataLinear(training)\n",
        "test_y_lin = torch.tensor([i for i in range(10) for j in range(aux[i])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEudp2XbtxSn",
        "outputId": "fc5ef4c4-5909-4e70-c534-d8023a9e1698"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n",
            "[5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting data for CNN model\n",
        "train_x_cnn, aux = getDataCnn(training)\n",
        "train_y_cnn = torch.tensor([i for i in range(10) for j in range(aux[i])])\n",
        "\n",
        "test_x_cnn, aux = getDataCnn(testing)\n",
        "test_y_cnn = torch.tensor([i for i in range(10) for j in range(aux[i])])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gh_HkXFHuDSQ",
        "outputId": "2396bd9d-8e09-4aaf-e433-a8cd979da51a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n",
            "[980, 1135, 1032, 1010, 982, 892, 958, 1028, 974, 1009]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_lin.shape, train_y_lin.shape, test_x_lin.shape, test_y_lin.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8ZVoiw5uXTM",
        "outputId": "85175a3d-a4ea-463f-b80e-0ba07a1cde49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 784]),\n",
              " torch.Size([60000]),\n",
              " torch.Size([60000, 784]),\n",
              " torch.Size([60000]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_cnn.shape, train_y_cnn.shape, test_x_cnn.shape, test_y_cnn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq6C9l14u4S4",
        "outputId": "a465b4ea-f15f-4716-9717-94fca6e57a60"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([60000, 1, 28, 28]),\n",
              " torch.Size([60000]),\n",
              " torch.Size([10000, 1, 28, 28]),\n",
              " torch.Size([10000]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# manually\n",
        "def foreward_pass(train_x):\n",
        "  return F.sigmoid(train_x@weights + bias)  # make sure the sigmoid does not mess up the backwards pass\n",
        "\n",
        "\n",
        "def backward_pass(train_x, train_y):\n",
        "  preds = foreward_pass(train_x)\n",
        "  loss = F.cross_entropy(preds, train_y)\n",
        "  loss.backward()\n",
        "\n",
        "\n",
        "def accuracy(preds, test_y):\n",
        "  return (preds.argmax(dim=1) == test_y).float().mean()"
      ],
      "metadata": {
        "id": "49_D3I4_vA4D"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights = torch.randn(784, 10) / math.sqrt(784)  # directly from input to output.\n",
        "weights.requires_grad_()\n",
        "\n",
        "bias = torch.zeros(10)\n",
        "bias.requires_grad_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdIJxUIQvFdM",
        "outputId": "f8622fcc-4460-472f-9640-16a1da4d5726"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 50\n",
        "lr = 6.0  # it feels like im overfitting as hell with this\n",
        "\n",
        "# training\n",
        "for epoch in range(num_epochs):\n",
        "  backward_pass(train_x_lin, train_y_lin)\n",
        "  with torch.no_grad():\n",
        "    weights -= weights.grad * lr # remeber that grad is an attr of Tensor()\n",
        "    bias += bias.grad * lr\n",
        "    weights.grad.zero_()\n",
        "    bias.grad.zero_()\n",
        "\n",
        "# testing\n",
        "pred = foreward_pass(test_x_lin)\n",
        "print(f'accuarcy: {accuracy(pred, test_y_lin)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlhWbr-AvIqv",
        "outputId": "e47d1c80-3b21-4bd3-8c02-f49397b19731"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuarcy: 0.8715166449546814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for the models used below\n",
        "def learn_(model, optimizer,train_dataloader, test_dataloader, num_epochs):\n",
        "  for epoch in range(num_epochs):\n",
        "    model.train()  # where the foreward method is called\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "      inputs, labels = batch\n",
        "      optimizer.zero_grad()\n",
        "      outputs = model(inputs)\n",
        "      loss = criterion(outputs, labels)  # here\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      running_loss += loss.item()\n",
        "\n",
        "    epoch_loss = running_loss / len(train_dataloader)\n",
        "\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "      for batch_x, batch_y in test_dataloader:\n",
        "        outputs = model(batch_x)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += batch_y.size(0)\n",
        "        correct += (predicted == batch_y).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.2f}%')"
      ],
      "metadata": {
        "id": "Lw_Z9havwml8"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# linear models"
      ],
      "metadata": {
        "id": "Pjr6yrBAweuK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_Linear(nn.Module):  # just linear\n",
        "  def __init__(self):\n",
        "    super(MNIST_Linear, self).__init__()\n",
        "    self.lin1 = nn.Linear(28*28, 10)\n",
        "    self.lin2 = nn.Linear(10, 10)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.Softmax()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.lin1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.lin2(x)\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "\n",
        "  def say_hi(self):\n",
        "    print(\"Hi, Im a Linear Model!\")"
      ],
      "metadata": {
        "id": "BMNBGX6PvYkJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linLearner0 = MNIST_Linear()\n",
        "linLearner1 = MNIST_Linear()  # make sure the variables are good\n",
        "\n",
        "training_data_linear = TensorDataset(train_x_lin, train_y_lin)\n",
        "testing_data_linear = TensorDataset(test_x_lin, test_y_lin)\n",
        "\n",
        "train_dataloader_linear = TorchDataLoader(training_data_linear, batch_size=64, shuffle=True)\n",
        "test_dataloader_linear = TorchDataLoader(testing_data_linear, batch_size=64, shuffle=True)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() # loss\n",
        "optimizer0 = torch.optim.SGD(linLearner0.parameters(), lr=0.02) # extract parameters directly\n",
        "optimizer1 = torch.optim.Adam(linLearner1.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "rHm5LaPvwh1J"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn_(linLearner0, optimizer0, train_dataloader_linear, test_dataloader_linear, 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw_z09_A2j6A",
        "outputId": "354c989f-c2dd-4ab0-cbc9-e3ed4fc06d4c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch[0].shape: torch.Size([64, 784]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 784])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [1/7], Loss: 2.2328, Accuracy: 45.36%\n",
            "batch[0].shape: torch.Size([64, 784]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 784])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [2/7], Loss: 1.9311, Accuracy: 72.53%\n",
            "batch[0].shape: torch.Size([64, 784]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 784])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [3/7], Loss: 1.7675, Accuracy: 74.00%\n",
            "batch[0].shape: torch.Size([64, 784]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 784])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [4/7], Loss: 1.7119, Accuracy: 81.26%\n",
            "batch[0].shape: torch.Size([64, 784]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 784])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [5/7], Loss: 1.6777, Accuracy: 82.32%\n",
            "batch[0].shape: torch.Size([64, 784]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 784])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [6/7], Loss: 1.6615, Accuracy: 82.86%\n",
            "batch[0].shape: torch.Size([64, 784]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 784])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [7/7], Loss: 1.6518, Accuracy: 83.20%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "it seems like 83% is pretty good for not having any edge detection"
      ],
      "metadata": {
        "id": "7LCKQxRM2xU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learn_(linLearner1, optimizer1, train_dataloader_linear, test_dataloader_linear, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTrRm-4w263_",
        "outputId": "a4978c62-329f-4640-bc4c-5bb817a5e3d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch[0].shape: torch.Size([64, 784]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 784])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [1/3], Loss: 1.6590, Accuracy: 83.89%\n",
            "batch[0].shape: torch.Size([64, 784]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 784])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [2/3], Loss: 1.6280, Accuracy: 84.01%\n",
            "batch[0].shape: torch.Size([64, 784]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 784])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [3/3], Loss: 1.6232, Accuracy: 83.83%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we get just a bit higher with adams optimizer but it seems at 80ish percent is the highest accuracy you can get with just a linear model"
      ],
      "metadata": {
        "id": "ROTJ0yDT3HHk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN models"
      ],
      "metadata": {
        "id": "FHZ3FfVs3Q1Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_CNN(nn.Module):  # trying CNN\n",
        "  def __init__(self):\n",
        "    super(MNIST_CNN, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "    self.pool = nn.MaxPool2d(2, 2)\n",
        "    self.fc1 = nn.Linear(64*7*7, 20)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.fc2 = nn.Linear(20, 10)\n",
        "    self.log_softmax = nn.LogSoftmax()\n",
        "    # check if you needd the log softmax\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.pool(self.relu(self.conv1(x)))\n",
        "    x = self.pool(self.relu(self.conv2(x)))\n",
        "    x = x.flatten(start_dim=1)\n",
        "    x = self.relu(self.fc1(x))\n",
        "    x = self.fc2(x)\n",
        "    x = self.log_softmax(x)\n",
        "    return x\n",
        "\n",
        "  def say_hi(self):\n",
        "    print(\"Hi, Im a CNN Model!\")"
      ],
      "metadata": {
        "id": "YYvbGqaT4a6e"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CNN models\n",
        "convLearner2 = MNIST_CNN()\n",
        "convLearner3 = MNIST_CNN()\n",
        "\n",
        "training_data_cnn = TensorDataset(train_x_cnn, train_y_cnn)\n",
        "testing_data_cnn = TensorDataset(test_x_cnn, test_y_cnn)\n",
        "\n",
        "train_dataloader_cnn = TorchDataLoader(training_data_cnn, batch_size=64, shuffle=True)\n",
        "test_dataloader_cnn = TorchDataLoader(testing_data_cnn, batch_size=64, shuffle=True)\n",
        "\n",
        "optimizer2 = torch.optim.SGD(convLearner2.parameters(), lr=0.01)\n",
        "optimizer3 = torch.optim.Adam(convLearner3.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "JJaTfbYi4hhK"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn_(convLearner2, optimizer2, train_dataloader_cnn, test_dataloader_cnn, 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8zEYYJN35iu",
        "outputId": "3428d877-876b-4d9c-a270-795d4ef9ff7f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch[0].shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 1, 28, 28])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [1/7], Loss: 1.0514, Accuracy: 90.75%\n",
            "batch[0].shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 1, 28, 28])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [2/7], Loss: 0.2789, Accuracy: 93.49%\n",
            "batch[0].shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 1, 28, 28])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [3/7], Loss: 0.1929, Accuracy: 93.90%\n",
            "batch[0].shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 1, 28, 28])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [4/7], Loss: 0.1464, Accuracy: 96.55%\n",
            "batch[0].shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 1, 28, 28])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [5/7], Loss: 0.1189, Accuracy: 96.58%\n",
            "batch[0].shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 1, 28, 28])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [6/7], Loss: 0.1009, Accuracy: 97.55%\n",
            "batch[0].shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 1, 28, 28])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [7/7], Loss: 0.0901, Accuracy: 97.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn_(convLearner3, optimizer3, train_dataloader_cnn, test_dataloader_cnn, 3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHR-6C03P7O7",
        "outputId": "17962a47-c73a-45ea-fee9-5d9fc1969c80"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1736: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return self._call_impl(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch[0].shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 1, 28, 28])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [1/3], Loss: 0.2150, Accuracy: 96.78%\n",
            "batch[0].shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 1, 28, 28])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [2/3], Loss: 0.1138, Accuracy: 96.67%\n",
            "batch[0].shape: torch.Size([64, 1, 28, 28]) torch.Size([64])\n",
            "inputs.shape; torch.Size([64, 1, 28, 28])\n",
            "labels.shape torch.Size([64])\n",
            "outputs.shape torch.Size([64, 10])\n",
            "Epoch [3/3], Loss: 0.0989, Accuracy: 97.40%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in this case adams wasn't really that much better. but 97% seems pretty good?"
      ],
      "metadata": {
        "id": "Z8N19BzyQf86"
      }
    }
  ]
}
